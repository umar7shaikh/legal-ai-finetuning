{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d5aff126f6b4d399872bfb31a5b06aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0eb18fdd8044a90a853340bd8a1ceb6",
              "IPY_MODEL_aff4b7d5221d4b1faf02a615393c7b8c",
              "IPY_MODEL_c5af1fb6d6054e88a2fdcd5499fe6bd1"
            ],
            "layout": "IPY_MODEL_8891b8ed2701453aa019440f9c790097"
          }
        },
        "a0eb18fdd8044a90a853340bd8a1ceb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7986626d7c034155b770ceda92a0bca0",
            "placeholder": "​",
            "style": "IPY_MODEL_41c99bd7b2554f3eb8611dceee0fe68f",
            "value": "Map: 100%"
          }
        },
        "aff4b7d5221d4b1faf02a615393c7b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef00f4cce114259964542991c9d597e",
            "max": 14543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7928ba8f560d43d0ac89b18013de994f",
            "value": 14543
          }
        },
        "c5af1fb6d6054e88a2fdcd5499fe6bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31431a29eb84cfab985a1d10e761708",
            "placeholder": "​",
            "style": "IPY_MODEL_2a3a49e586474ccfa718373b706c60db",
            "value": " 14543/14543 [00:00&lt;00:00, 39235.73 examples/s]"
          }
        },
        "8891b8ed2701453aa019440f9c790097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7986626d7c034155b770ceda92a0bca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c99bd7b2554f3eb8611dceee0fe68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ef00f4cce114259964542991c9d597e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7928ba8f560d43d0ac89b18013de994f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c31431a29eb84cfab985a1d10e761708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a3a49e586474ccfa718373b706c60db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b60ba067de0a4cf79745470aea3daf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0761e051318c419982214e73718afbcb",
              "IPY_MODEL_4111d848b1114057ad773c52b9913bf2",
              "IPY_MODEL_0e86d6135f0d46dd91eaad78c3f86b8d"
            ],
            "layout": "IPY_MODEL_6e9f82c80be745c8bf9e9ae325c72229"
          }
        },
        "0761e051318c419982214e73718afbcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb31961265344f5a5fba059b34c54b1",
            "placeholder": "​",
            "style": "IPY_MODEL_6f40389758134618bd2b364ed75109f0",
            "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
          }
        },
        "4111d848b1114057ad773c52b9913bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3271416bc61e4635889d96dff6e3a602",
            "max": 14543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9aae63d757784de09691b61301fc5213",
            "value": 14543
          }
        },
        "0e86d6135f0d46dd91eaad78c3f86b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6251e31fc6624123a2ce8dd60bcaba1a",
            "placeholder": "​",
            "style": "IPY_MODEL_7f38658b585e4edb82539ebc8acb63ba",
            "value": " 14543/14543 [00:20&lt;00:00, 1017.10 examples/s]"
          }
        },
        "6e9f82c80be745c8bf9e9ae325c72229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb31961265344f5a5fba059b34c54b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f40389758134618bd2b364ed75109f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3271416bc61e4635889d96dff6e3a602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aae63d757784de09691b61301fc5213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6251e31fc6624123a2ce8dd60bcaba1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f38658b585e4edb82539ebc8acb63ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OHkd27-P-6a"
      },
      "outputs": [],
      "source": [
        "# Step1: Create & Setup hugging face API token in Collab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth # install unsloth\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdsxiRgVQl03",
        "outputId": "32d140fe-523b-4023-93cb-a70190996c2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (2025.5.4)\n",
            "Collecting git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-qiy32y5h\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-qiy32y5h\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 5bf1ce073ff6db8f4fd282b40686d8b4d780e942\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.5.4-py3-none-any.whl size=265196 sha256=9836104214ffde77ac6c27bbf89f6a72e010dea3a8788c8f492bbe0aadd84245\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-176me3he/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "  Attempting uninstall: unsloth\n",
            "    Found existing installation: unsloth 2025.5.4\n",
            "    Uninstalling unsloth-2025.5.4:\n",
            "      Successfully uninstalled unsloth-2025.5.4\n",
            "Successfully installed unsloth-2025.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3: Import necessary libraries\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from unsloth import is_bfloat16_supported\n",
        "from huggingface_hub import login\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY4Zqy4FQrfP",
        "outputId": "cb7ecc86-7ede-4e5f-d3b0-e217360df596"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token)"
      ],
      "metadata": {
        "id": "-d697UpfSNXt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Check GPU availability\n",
        "# Test if CUDA is available\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"GPU device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZROikBRwSWg8",
        "outputId": "40dee03d-2dc4-49bc-e0d5-1f9b410d38da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "max_sequence_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = max_sequence_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlMjOhNzSZmb",
        "outputId": "4736b80d-f708-4836-d598-889912c5eff4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.5.4: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step6: Setup system prompt (Legal Version)\n",
        "prompt_style = \"\"\"\n",
        "Below is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\n",
        "\n",
        "Before crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\n",
        "\n",
        "### Task:\n",
        "You are a legal expert specializing in Indian Constitution, IPC, and CrPC. Answer the legal question below using your advanced knowledge.\n",
        "\n",
        "### Query:\n",
        "{}\n",
        "\n",
        "### Answer:\n",
        "{}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cY8QuLz6U2Ql"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step7: Run Inference on the model (Legal Version)\n",
        "\n",
        "# Define a test legal question\n",
        "question = \"\"\"Under what circumstances can a person be granted anticipatory bail under CrPC?\"\"\"\n",
        "\n",
        "# Prepare the model for inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# Tokenize the input using the original prompt style\n",
        "inputs = tokenizer(\n",
        "    [prompt_style.format(question, \"\")],\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate a response (keeping original parameters)\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=1200,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Decode and print the full response\n",
        "response = tokenizer.batch_decode(outputs)[0]\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51YHZ2lEU2iW",
        "outputId": "17c0a421-25da-4961-ac16-2a668bec7d37"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<｜begin▁of▁sentence｜>\n",
            "Below is a task description along with additional context provided in the input section. Your goal is to provide a well-reasoned response that effectively addresses the request.\n",
            "\n",
            "Before crafting your answer, take a moment to carefully analyze the question. Develop a clear, step-by-step thought process to ensure your response is both logical and accurate.\n",
            "\n",
            "### Task:\n",
            "You are a legal expert specializing in Indian Constitution, IPC, and CrPC. Answer the legal question below using your advanced knowledge.\n",
            "\n",
            "### Query:\n",
            "Under what circumstances can a person be granted anticipatory bail under CrPC?\n",
            "\n",
            "### Answer:\n",
            "\n",
            "**Step-by-Step Explanation:**\n",
            "\n",
            "1. **Understanding the Term:**\n",
            "   - Anticipatory bail is a type of bail granted by a court to an accused person before their arrest, ensuring they are released from custody.\n",
            "   - It is typically sought when there is a fear of arrest due to a pending legal proceeding.\n",
            "\n",
            "2. **Legal Basis:**\n",
            "   - **Section 498 of the CrPC** deals with anticipatory bail. It states that a High Court or a Court of Session can grant bail to a person if such bail is considered necessary to prevent the accused from committing a further offense or from absconding or causing harm to himself or others.\n",
            "\n",
            "3. **Conditions for Granting Anticipatory Bail:**\n",
            "   - **Moral Culpability:** The accused should show that they are not likely to commit any further offenses. This can be demonstrated by showing that they have strong roots in society, a stable family, and a history of good conduct.\n",
            "   - **Likelihood of Flight:** The court must be satisfied that the accused is not likely to abscond or flee from justice.\n",
            "   - **Need for Bail:** The bail must be necessary to prevent the accused from causing harm to themselves or others, or to prevent the commission of a further offense.\n",
            "\n",
            "4. **Procedural Steps:**\n",
            "   - **Application Submission:** The accused must move the appropriate court (High Court or Court of Session) with a written application for anticipatory bail.\n",
            "   - **Notice to Public Prosecutor:** The court must be notified to the Public Prosecutor (PP) about the application.\n",
            "   - **Hearing and Decision:** The court will hear the application and decide whether to grant bail based on the aforementioned conditions.\n",
            "\n",
            "5. **Supreme Court Precedents:**\n",
            "   - The Supreme Court in various cases has emphasized the need for courts to carefully consider the above conditions before granting anticipatory bail. For instance, in the case of *Nandlal Sharma vs. State of Bihar*, the Court highlighted the importance of ensuring that granting bail does not undermine the fairness of the trial or lead to the accused fleeing from justice.\n",
            "\n",
            "6. **Judicial Discretion:**\n",
            "   - The decision to grant anticipatory bail is within the discretion of the court, but it must be exercised judiciously to ensure that it serves the ends of justice.\n",
            "\n",
            "7. **Conclusion:**\n",
            "   - Anticipatory bail is granted when the court is satisfied that the accused does not pose a threat to public safety or justice and that granting bail would not undermine the ongoing legal proceedings.\n",
            "\n",
            "**Final Answer:**\n",
            "Anticipatory bail under CrPC can be granted by a High Court or a Court of Session if the accused demonstrates that they are not likely to commit further offenses, are not a flight risk, and that granting bail is necessary to prevent harm to themselves or others. The court must consider these factors and grant bail accordingly, ensuring it serves justice.\n",
            "</think>\n",
            "\n",
            "**Anticipatory Bail Under CrPC: Conditions and Process**\n",
            "\n",
            "Anticipatory bail is a legal mechanism granted by courts to release an accused person from custody before their arrest, ensuring they are not subjected to unnecessary detention. This bail is typically sought when there is a fear of arrest due to pending legal proceedings. Here's a structured overview of the conditions and process involved:\n",
            "\n",
            "### Conditions for Granting Anticipatory Bail:\n",
            "1. **Moral Culpability:** The accused must demonstrate that they are unlikely to commit further offenses. This is evaluated based on their history, including family ties, stability, and past conduct.\n",
            "2. **Likelihood of Flight:** The court must be satisfied that the accused is not likely to abscond or flee from justice. Factors such as ties to the community and a stable lifestyle are considered.\n",
            "3. **Need for Bail:** Bail must be necessary to prevent harm to the accused, themselves, or others, or to prevent further offenses.\n",
            "\n",
            "### Procedural Steps:\n",
            "1. **Application Submission:** The accused files a written application with a High Court or Court of Session.\n",
            "2. **Notice to Public Prosecutor:** The court informs the Public Prosecutor (PP) about the application.\n",
            "3. **Hearing and Decision:** The court reviews the application, considering the conditions, and decides whether to grant bail.\n",
            "\n",
            "### Supreme Court Precedents:\n",
            "The Supreme Court has emphasized the need for courts to carefully assess these conditions. For instance, in *Nandlal Sharma vs. State of Bihar*, the Court underscored the importance of ensuring bail does not undermine trial fairness or allow flight.\n",
            "\n",
            "### Judicial Discretion:\n",
            "The decision to grant anticipatory bail is within the court's discretion, exercised judiciously to serve justice.\n",
            "\n",
            "### Conclusion:\n",
            "Anticipatory bail is granted when the court is confident that the accused does not pose a threat to public safety or justice and that bail would not undermine ongoing legal proceedings.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[0].split(\"### Answer\")[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "YxvpupJ0U2p_",
        "outputId": "d058b05c-c3a0-46c6-9491-05f972a64b18"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1ef6e9f2268f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"### Answer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/datasets/Techmaestro369/indian-legal-texts-finetuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymx2-LhYU2vM",
        "outputId": "93e6ef02-98d9-49e4-aa8b-2dc8e48ff3f7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indian-legal-texts-finetuning'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 13 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (13/13), 560.82 KiB | 2.53 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "def load_json_to_dataset(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    return Dataset.from_list(data)\n",
        "\n",
        "# Load each JSON file\n",
        "constitution = load_json_to_dataset(\"indian-legal-texts-finetuning/constitution_qa.json\")\n",
        "ipc = load_json_to_dataset(\"indian-legal-texts-finetuning/ipc_qa.json\")\n",
        "crpc = load_json_to_dataset(\"indian-legal-texts-finetuning/crpc_qa.json\")"
      ],
      "metadata": {
        "id": "nl02FUTLU20_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "def load_json_to_dataset(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    return Dataset.from_list(data)\n",
        "\n",
        "# Load each JSON file\n",
        "constitution = load_json_to_dataset(\"indian-legal-texts-finetuning/constitution_qa.json\")\n",
        "ipc = load_json_to_dataset(\"indian-legal-texts-finetuning/ipc_qa.json\")\n",
        "crpc = load_json_to_dataset(\"indian-legal-texts-finetuning/crpc_qa.json\")"
      ],
      "metadata": {
        "id": "oGi85cuaTu7G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "legal_dataset = concatenate_datasets([constitution, ipc, crpc])\n",
        "legal_dataset = legal_dataset.shuffle(seed=42)  # Optional shuffling"
      ],
      "metadata": {
        "id": "irDuMq4zhTeK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(legal_dataset)\n",
        "print(legal_dataset[0])  # Check a sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v2tRyfvhaLP",
        "outputId": "7dfc7c35-d548-4787-849c-69649f96449a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'answer'],\n",
            "    num_rows: 14543\n",
            "})\n",
            "{'question': 'What does it mean when a Bill has been agreed to by both Houses, either without amendment or with such amendments only as are agreed to by both Houses?', 'answer': 'It means that the Bill is considered passed by the Houses of Parliament.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which tells the model when to stop generating text during training\n",
        "EOS_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rKzgCZhPhd9h",
        "outputId": "6f345451-c748-44bf-9bcc-38ea0a312e3f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<｜end▁of▁sentence｜>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Finetuning (Legal Version)\n",
        "# Updated training prompt style with legal focus\n",
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
        "\n",
        "### Instruction:\n",
        "You are a legal expert with advanced knowledge of Indian Constitution, IPC, and CrPC.\n",
        "Please answer the following legal question.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Legal Reasoning:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "\n",
        "### Response:\n",
        "{}\"\"\""
      ],
      "metadata": {
        "id": "0NE2nA_nh639"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare legal data for fine-tuning\n",
        "def preprocess_input_data(examples):\n",
        "    inputs = examples[\"question\"]  # Changed from \"Question\" to match legal dataset\n",
        "    outputs = examples[\"answer\"]   # Changed from \"Response\"\n",
        "\n",
        "    texts = []\n",
        "\n",
        "    for input, output in zip(inputs, outputs):\n",
        "        # Generate synthetic legal reasoning if Complex_CoT not available\n",
        "        cot = f\"\"\"1. Jurisdiction: Identify relevant code (IPC/CrPC/Constitution)\n",
        "2. Key Terms: {', '.join(input.split()[:3])}\n",
        "3. Applicable Sections: [Relevant sections]\n",
        "4. Precedent: [Landmark case if known]\n",
        "5. Conclusion: {output[:50]}...\"\"\"  # First 50 chars of answer\n",
        "\n",
        "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "\n",
        "    return {\"text\": texts}  # Changed key to singular \"text\" for SFTTrainer compatibility"
      ],
      "metadata": {
        "id": "fDfRQhQXiHz_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected fine-tuning dataset preparation\n",
        "finetune_dataset = legal_dataset.map(\n",
        "    preprocess_input_data,\n",
        "    batched=True,\n",
        "    remove_columns=legal_dataset.column_names  # Clean up original columns\n",
        ")\n",
        "\n",
        "# Verify the processed dataset\n",
        "print(finetune_dataset)\n",
        "print(finetune_dataset[0]['text'])  # Inspect a sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500,
          "referenced_widgets": [
            "4d5aff126f6b4d399872bfb31a5b06aa",
            "a0eb18fdd8044a90a853340bd8a1ceb6",
            "aff4b7d5221d4b1faf02a615393c7b8c",
            "c5af1fb6d6054e88a2fdcd5499fe6bd1",
            "8891b8ed2701453aa019440f9c790097",
            "7986626d7c034155b770ceda92a0bca0",
            "41c99bd7b2554f3eb8611dceee0fe68f",
            "9ef00f4cce114259964542991c9d597e",
            "7928ba8f560d43d0ac89b18013de994f",
            "c31431a29eb84cfab985a1d10e761708",
            "2a3a49e586474ccfa718373b706c60db"
          ]
        },
        "id": "JX_GI7BriTJA",
        "outputId": "71924613-c7ab-4ed6-fecb-edef648393b1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14543 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d5aff126f6b4d399872bfb31a5b06aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 14543\n",
            "})\n",
            "Below is an instruction that describes a task, paired with an input that provides further context.\n",
            "Write a response that appropriately completes the request.\n",
            "Before answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n",
            "\n",
            "### Instruction:\n",
            "You are a legal expert with advanced knowledge of Indian Constitution, IPC, and CrPC.\n",
            "Please answer the following legal question.\n",
            "\n",
            "### Question:\n",
            "What does it mean when a Bill has been agreed to by both Houses, either without amendment or with such amendments only as are agreed to by both Houses?\n",
            "\n",
            "### Legal Reasoning:\n",
            "<think>\n",
            "1. Jurisdiction: Identify relevant code (IPC/CrPC/Constitution)\n",
            "2. Key Terms: What, does, it\n",
            "3. Applicable Sections: [Relevant sections]\n",
            "4. Precedent: [Landmark case if known]\n",
            "5. Conclusion: It means that the Bill is considered passed by the...\n",
            "</think>\n",
            "\n",
            "### Response:\n",
            "It means that the Bill is considered passed by the Houses of Parliament.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step9: Setup/Apply LoRA finetuning to the model\n",
        "\n",
        "model_lora = FastLanguageModel.get_peft_model(\n",
        "    model = model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3047,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd9zcU4Jihkp",
        "outputId": "c28ed69b-74da-45d5-fe07-fc4bf56f7c8e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if hasattr(model, '_unwrapped_old_generate'):\n",
        "    del model._unwrapped_old_generate"
      ],
      "metadata": {
        "id": "bIu8MPcAjEsP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected SFTTrainer Setup for Legal Fine-Tuning\n",
        "trainer = SFTTrainer(\n",
        "    model=model_lora,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=finetune_dataset,\n",
        "    dataset_text_field=\"text\",  # Changed from \"texts\" to match your preprocessed data\n",
        "    max_seq_length=max_sequence_length,\n",
        "    dataset_num_proc=2,  # Increased from 1 for faster preprocessing\n",
        "    packing=True,  # Enable for more efficient training\n",
        "\n",
        "    # Optimized TrainingArguments\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=1,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"cosine\",  # Better than linear for legal tasks\n",
        "        seed=3407,\n",
        "        output_dir=\"legal_outputs\",  # Changed from generic \"outputs\"\n",
        "        report_to=\"wandb\",  # Enable if using Weights & Biases\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=20\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b60ba067de0a4cf79745470aea3daf29",
            "0761e051318c419982214e73718afbcb",
            "4111d848b1114057ad773c52b9913bf2",
            "0e86d6135f0d46dd91eaad78c3f86b8d",
            "6e9f82c80be745c8bf9e9ae325c72229",
            "ddb31961265344f5a5fba059b34c54b1",
            "6f40389758134618bd2b364ed75109f0",
            "3271416bc61e4635889d96dff6e3a602",
            "9aae63d757784de09691b61301fc5213",
            "6251e31fc6624123a2ce8dd60bcaba1a",
            "7f38658b585e4edb82539ebc8acb63ba"
          ]
        },
        "id": "mrKtWHbxjVfC",
        "outputId": "0a45cecd-1942-4784-a3e8-f0ef8f319af1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/14543 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b60ba067de0a4cf79745470aea3daf29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Hugging Face's packing is currently buggy - we're disabling it for now!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup W&B for Legal Fine-Tuning\n",
        "from google.colab import userdata\n",
        "import wandb\n",
        "\n",
        "# 1. Secure Login\n",
        "wnb_token = userdata.get(\"WANDB_API_TOKEN\")  # Retrieve from Colab secrets\n",
        "wandb.login(key=wnb_token)\n",
        "\n",
        "# 2. Initialize Run with Legal-Specific Config\n",
        "run = wandb.init(\n",
        "    project='Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts',  # Updated project name\n",
        "    job_type=\"legal_finetuning\",  # More specific job type\n",
        "    config={\n",
        "        \"model\": \"DeepSeek-R1-Llama-8B\",\n",
        "        \"task\": \"Indian Legal Q&A\",\n",
        "        \"dataset\": \"IPC/CrPC/Constitution\",\n",
        "        \"peft\": \"LoRA\",\n",
        "        \"batch_size\": 2,\n",
        "        \"lr\": 2e-4\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "-ss5uazBjhBc",
        "outputId": "832a7bf6-ed73-41fb-d5ef-12df627bcf82"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmdumarshaikh\u001b[0m (\u001b[33mmdumarshaikh-trinity-academy-of-engineering-pune\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250515_200844-3okyhd7i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts/runs/3okyhd7i' target=\"_blank\">vivid-yogurt-1</a></strong> to <a href='https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts' target=\"_blank\">https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts/runs/3okyhd7i' target=\"_blank\">https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts/runs/3okyhd7i</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "mj84fFknkDgY",
        "outputId": "495645b6-b781-44e1-cb97-b9a6cadb9900"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 14,543 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 06:50, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.281200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.586900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.482300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.419400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.439500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.449900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "PKMIfIlCkNtw",
        "outputId": "d248cb5c-1903-4cd4-9f46-04a06d6ef746"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▂▁▂▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▃▂▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>4797000430043136.0</td></tr><tr><td>train/epoch</td><td>0.033</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.34037</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4499</td></tr><tr><td>train_loss</td><td>0.77654</td></tr><tr><td>train_runtime</td><td>420.4081</td></tr><tr><td>train_samples_per_second</td><td>1.142</td></tr><tr><td>train_steps_per_second</td><td>0.143</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vivid-yogurt-1</strong> at: <a href='https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts/runs/3okyhd7i' target=\"_blank\">https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts/runs/3okyhd7i</a><br> View project at: <a href='https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts' target=\"_blank\">https://wandb.ai/mdumarshaikh-trinity-academy-of-engineering-pune/Fine-tune-DeepSeek-R1-on-Indian-Legal-Texts</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250515_200844-3okyhd7i/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step10: Testing after fine-tuning (Legal Version)\n",
        "question = \"\"\"Under what circumstances can anticipatory bail be granted under CrPC?\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model_lora)\n",
        "\n",
        "# Tokenize using the same prompt style\n",
        "inputs = tokenizer(\n",
        "    [prompt_style.format(question, \"\")],  # Unchanged prompt structure\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate response (same parameters)\n",
        "outputs = model_lora.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=400,  # Reduced from 1200 for legal answers\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Decode and print\n",
        "response = tokenizer.batch_decode(outputs)[0]\n",
        "print(response.split(\"### Answer:\")[1].strip())  # Same extraction method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCQFyQ6Kl2yC",
        "outputId": "c2a7c5cb-3b64-4cf1-9ded-419777c06370"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Under the circumstances specified in sub-section (1) of section 498, anticipatory bail may be granted by the Court.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sU5QHHxAm1bY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q5NBv_7Mnmnr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}